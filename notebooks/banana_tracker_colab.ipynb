{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BananaTracker - Multi-Object Tracking with SAM2.1 + Cutie\n",
    "\n",
    "This notebook demonstrates the complete MOT tracking pipeline using:\n",
    "- **YOLOv8** for object detection\n",
    "- **ByteTrack-based tracker** for multi-object tracking\n",
    "- **SAM2.1** for high-quality mask generation from bounding boxes\n",
    "- **Cutie** for temporal mask propagation\n",
    "\n",
    "The mask module enhances tracking by providing pixel-level precision that improves association when objects are close together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics opencv-python-headless tqdm\n",
    "!pip install lap cython_bbox  # For ByteTrack tracker core\n",
    "\n",
    "# Install SAM2.1 dependencies (HuggingFace transformers)\n",
    "!pip install transformers>=4.35.0 huggingface_hub\n",
    "\n",
    "# Install Cutie dependencies\n",
    "!pip install omegaconf hydra-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Clone Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone BananaTracker repository\n",
    "if not os.path.exists('bananatracker'):\n",
    "    !git clone https://github.com/USER/bananatracker.git\n",
    "\n",
    "# Clone Cutie for temporal mask propagation\n",
    "if not os.path.exists('Cutie'):\n",
    "    !git clone https://github.com/hkchengrex/Cutie.git\n",
    "\n",
    "# Create symlink for Cutie in mask_propagation folder\n",
    "os.makedirs('bananatracker/bananatracker/mask_propagation', exist_ok=True)\n",
    "if not os.path.exists('bananatracker/bananatracker/mask_propagation/Cutie'):\n",
    "    os.symlink('/content/Cutie', 'bananatracker/bananatracker/mask_propagation/Cutie')\n",
    "\n",
    "# Download Cutie weights\n",
    "os.makedirs('Cutie/weights', exist_ok=True)\n",
    "if not os.path.exists('Cutie/weights/cutie-base-mega.pth'):\n",
    "    !wget -P Cutie/weights https://github.com/hkchengrex/Cutie/releases/download/v1.0/cutie-base-mega.pth\n",
    "\n",
    "# Install BananaTracker in development mode\n",
    "%cd bananatracker\n",
    "!pip install -e .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: SAM2.1 Model Configuration\n",
    "\n",
    "Configure SAM2.1 model settings. You can choose different model sizes:\n",
    "- `facebook/sam2.1-hiera-tiny` - Fastest, lower quality\n",
    "- `facebook/sam2.1-hiera-small` - Good balance\n",
    "- `facebook/sam2.1-hiera-base-plus` - Better quality\n",
    "- `facebook/sam2.1-hiera-large` - Best quality (recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title SAM2.1 Configuration { display-mode: \"form\" }\n",
    "\n",
    "# SAM2.1 Model Settings\n",
    "SAM2_MODEL_ID = \"facebook/sam2.1-hiera-large\"  #@param [\"facebook/sam2.1-hiera-tiny\", \"facebook/sam2.1-hiera-small\", \"facebook/sam2.1-hiera-base-plus\", \"facebook/sam2.1-hiera-large\"]\n",
    "SAM2_CHECKPOINT = \"\"  #@param {type:\"string\"} # Optional: local checkpoint path (leave empty to use HuggingFace)\n",
    "\n",
    "# HuggingFace Token (required for gated models, optional for SAM2)\n",
    "HF_TOKEN = \"\"  #@param {type:\"string\"}\n",
    "\n",
    "# Cutie Weights Path\n",
    "CUTIE_WEIGHTS = \"/content/Cutie/weights/cutie-base-mega.pth\"  #@param {type:\"string\"}\n",
    "\n",
    "print(f\"SAM2.1 Model: {SAM2_MODEL_ID}\")\n",
    "print(f\"SAM2.1 Checkpoint: {SAM2_CHECKPOINT if SAM2_CHECKPOINT else 'Using HuggingFace download'}\")\n",
    "print(f\"HF Token: {'Set' if HF_TOKEN else 'Not set (optional)'}\")\n",
    "print(f\"Cutie Weights: {CUTIE_WEIGHTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Tracker Configuration\n",
    "\n",
    "Configure the full tracking pipeline with detection, tracking, and mask settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/bananatracker')\n",
    "sys.path.insert(0, '/content/Cutie')\n",
    "\n",
    "from bananatracker import BananaTrackerConfig\n",
    "\n",
    "# Full configuration for hockey/sports tracking with mask enhancement\n",
    "config = BananaTrackerConfig(\n",
    "    # Detection Settings\n",
    "    yolo_weights=\"/content/HockeyAI_model_weight.pt\",  # Update with your model path\n",
    "    class_names=[\"Center Ice\", \"Faceoff\", \"Goalpost\", \"Goaltender\", \"Player\", \"Puck\", \"Referee\"],\n",
    "    track_classes=[3, 4, 5, 6],  # Goaltender, Player, Puck, Referee\n",
    "    special_classes=[5],          # Puck - max-conf only\n",
    "    detection_conf_thresh=0.5,    # General confidence threshold\n",
    "    detection_iou_thresh=0.7,     # IoU threshold for YOLO NMS\n",
    "\n",
    "    # Post-processing: Centroid-based deduplication\n",
    "    centroid_dedup_enabled=True,\n",
    "    centroid_dedup_max_distance=36,\n",
    "\n",
    "    # Tracker Settings (ByteTrack)\n",
    "    track_thresh=0.6,\n",
    "    track_buffer=30,\n",
    "    match_thresh=0.8,\n",
    "    fps=30,\n",
    "    cmc_method=\"orb\",  # Camera motion compensation\n",
    "\n",
    "    # Mask Module Settings (SAM2.1 + Cutie)\n",
    "    enable_masks=True,\n",
    "    sam2_model_id=SAM2_MODEL_ID,\n",
    "    sam2_checkpoint=SAM2_CHECKPOINT if SAM2_CHECKPOINT else None,\n",
    "    cutie_weights_path=CUTIE_WEIGHTS,\n",
    "    hf_token=HF_TOKEN if HF_TOKEN else None,\n",
    "    mask_start_frame=1,\n",
    "    mask_bbox_overlap_threshold=0.6,\n",
    "\n",
    "    # Visualization Settings\n",
    "    class_colors={\n",
    "        \"Goaltender\": (255, 165, 0),   # Orange\n",
    "        \"Player\": (255, 0, 0),          # Blue (BGR)\n",
    "        \"Puck\": (0, 255, 0),            # Green\n",
    "        \"Referee\": (0, 0, 255),         # Red\n",
    "    },\n",
    "    show_track_id=True,\n",
    "    show_masks=True,     # Enable mask overlay in visualization\n",
    "    mask_alpha=0.5,      # Mask transparency\n",
    "    line_thickness=2,\n",
    "\n",
    "    # Output Settings\n",
    "    output_video_path=\"/content/output_tracked_with_masks.mp4\",\n",
    "    output_txt_path=\"/content/results.txt\",\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "print(\"Configuration created!\")\n",
    "print(f\"\\nDetection:\")\n",
    "print(f\"  - Confidence threshold: {config.detection_conf_thresh}\")\n",
    "print(f\"  - Tracking classes: {config.track_classes}\")\n",
    "print(f\"\\nMask Module:\")\n",
    "print(f\"  - Enabled: {config.enable_masks}\")\n",
    "print(f\"  - SAM2.1 Model: {config.sam2_model_id}\")\n",
    "print(f\"  - Cutie Weights: {config.cutie_weights_path}\")\n",
    "print(f\"\\nVisualization:\")\n",
    "print(f\"  - Show masks: {config.show_masks}\")\n",
    "print(f\"  - Mask alpha: {config.mask_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Initialize Pipeline with SAM2.1 + Cutie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bananatracker import BananaTrackerPipeline\n",
    "\n",
    "# Initialize the pipeline (this will load SAM2.1 and Cutie models)\n",
    "print(\"Initializing pipeline...\")\n",
    "print(\"This may take a moment to download SAM2.1 model from HuggingFace...\")\n",
    "\n",
    "pipeline = BananaTrackerPipeline(config)\n",
    "\n",
    "print(\"\\nPipeline initialized!\")\n",
    "print(f\"  - Detector: YOLOv8\")\n",
    "print(f\"  - Tracker: BananaTracker (ByteTrack-based with mask enhancement)\")\n",
    "print(f\"  - Mask Module: {'SAM2.1 + Cutie' if pipeline.mask_manager else 'Disabled'}\")\n",
    "print(f\"  - CMC Method: {config.cmc_method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Validate SAM2.1 Mask Generation (Test Cell)\n",
    "\n",
    "This cell validates that SAM2.1 is working correctly by generating masks on a random frame from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Input video for testing\n",
    "TEST_VIDEO = \"/content/sample_video.mp4\"  # Update with your video path\n",
    "\n",
    "# Open video and get a random frame\n",
    "cap = cv2.VideoCapture(TEST_VIDEO)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video {TEST_VIDEO}\")\n",
    "else:\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    random_frame_idx = random.randint(0, total_frames - 1)\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, random_frame_idx)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if ret:\n",
    "        print(f\"Testing SAM2.1 on frame {random_frame_idx} of {total_frames}\")\n",
    "        \n",
    "        # Convert to RGB for SAM2.1\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Run detection to get bounding boxes\n",
    "        detections = pipeline.detector.detect(frame)\n",
    "        \n",
    "        if len(detections) > 0:\n",
    "            # Get bounding boxes (first 4 columns: x1, y1, x2, y2)\n",
    "            boxes_xyxy = detections[:, :4].tolist()\n",
    "            \n",
    "            print(f\"Detected {len(boxes_xyxy)} objects\")\n",
    "            \n",
    "            # Generate masks using SAM2.1\n",
    "            if pipeline.mask_manager is not None:\n",
    "                masks = pipeline.mask_manager._sam2_predict_boxes(frame_rgb, boxes_xyxy)\n",
    "                \n",
    "                print(f\"Generated {len(masks)} masks\")\n",
    "                print(f\"Mask shape: {masks.shape}\")\n",
    "                \n",
    "                # Visualize results\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "                \n",
    "                # Original frame\n",
    "                axes[0].imshow(frame_rgb)\n",
    "                axes[0].set_title(f'Original Frame #{random_frame_idx}')\n",
    "                axes[0].axis('off')\n",
    "                \n",
    "                # Frame with bounding boxes\n",
    "                frame_with_boxes = frame_rgb.copy()\n",
    "                for i, box in enumerate(boxes_xyxy):\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    cv2.rectangle(frame_with_boxes, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(frame_with_boxes, f'{i}', (x1, y1-10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "                axes[1].imshow(frame_with_boxes)\n",
    "                axes[1].set_title(f'Detected Objects ({len(boxes_xyxy)})')\n",
    "                axes[1].axis('off')\n",
    "                \n",
    "                # Combined masks overlay\n",
    "                colors = plt.cm.tab10(np.linspace(0, 1, 10))[:, :3] * 255\n",
    "                combined_mask = np.zeros_like(frame_rgb, dtype=np.float32)\n",
    "                for i, mask in enumerate(masks):\n",
    "                    color = colors[i % len(colors)]\n",
    "                    mask_3d = np.stack([mask, mask, mask], axis=-1)\n",
    "                    combined_mask += mask_3d * color / 255\n",
    "                \n",
    "                alpha = 0.5\n",
    "                frame_with_masks = frame_rgb.astype(np.float32)\n",
    "                mask_overlay = np.clip(combined_mask, 0, 255)\n",
    "                binary_mask = np.any(combined_mask > 0, axis=-1, keepdims=True)\n",
    "                frame_with_masks = np.where(\n",
    "                    binary_mask,\n",
    "                    frame_with_masks * alpha + mask_overlay * (1 - alpha),\n",
    "                    frame_with_masks\n",
    "                )\n",
    "                axes[2].imshow(frame_with_masks.astype(np.uint8))\n",
    "                axes[2].set_title('SAM2.1 Mask Overlay')\n",
    "                axes[2].axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig('/content/sam2_mask_validation.png', dpi=150, bbox_inches='tight')\n",
    "                plt.show()\n",
    "                \n",
    "                print(\"\\n✓ SAM2.1 mask generation validated successfully!\")\n",
    "                print(f\"  Validation image saved to: /content/sam2_mask_validation.png\")\n",
    "            else:\n",
    "                print(\"Warning: Mask module not initialized\")\n",
    "        else:\n",
    "            print(\"No objects detected in this frame. Try a different frame.\")\n",
    "    else:\n",
    "        print(f\"Error: Could not read frame {random_frame_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Run Full Tracking Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input video\n",
    "INPUT_VIDEO = \"/content/sample_video.mp4\"  # Update with your video path\n",
    "\n",
    "# Run tracking with mask enhancement\n",
    "print(f\"Processing video: {INPUT_VIDEO}\")\n",
    "print(f\"Mask module: {'Enabled' if config.enable_masks else 'Disabled'}\")\n",
    "print(\"\")\n",
    "\n",
    "all_tracks = pipeline.process_video(INPUT_VIDEO)\n",
    "\n",
    "print(f\"\\nProcessed {len(all_tracks)} frames\")\n",
    "print(f\"Output video: {config.output_video_path}\")\n",
    "print(f\"MOT results: {config.output_txt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Compress and Display Output Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Compress video for notebook display\n",
    "OUTPUT_COMPRESSED = \"/content/output_compressed.mp4\"\n",
    "!ffmpeg -y -i {config.output_video_path} -vcodec libx264 -crf 28 {OUTPUT_COMPRESSED}\n",
    "\n",
    "print(f\"Compressed video saved to: {OUTPUT_COMPRESSED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "OUTPUT_COMPRESSED = \"/content/output_compressed.mp4\"\n",
    "\n",
    "# Read and encode video\n",
    "mp4 = open(OUTPUT_COMPRESSED, 'rb').read()\n",
    "data_url = f\"data:video/mp4;base64,{b64encode(mp4).decode()}\"\n",
    "\n",
    "# Display video\n",
    "HTML(f'''\n",
    "<video width=\"800\" controls>\n",
    "  <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Frame-by-Frame Processing (Optional)\n",
    "\n",
    "For more control, process frames individually using the generator API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Process frame-by-frame with generator and access mask info\n",
    "# Uncomment to run\n",
    "\n",
    "# from bananatracker import BananaTrackerPipeline\n",
    "# \n",
    "# pipeline = BananaTrackerPipeline(config)\n",
    "# \n",
    "# for frame_id, frame, tracks, vis_frame in pipeline.process_video_generator(INPUT_VIDEO):\n",
    "#     # Get track info as dictionaries\n",
    "#     track_info = pipeline.get_track_info(tracks)\n",
    "#     \n",
    "#     # Access mask data\n",
    "#     prediction_mask = pipeline.prediction_mask\n",
    "#     tracklet_mask_dict = pipeline.tracklet_mask_dict\n",
    "#     \n",
    "#     # Process each track\n",
    "#     for info in track_info:\n",
    "#         track_id = info['track_id']\n",
    "#         mask_id = tracklet_mask_dict.get(track_id, None)\n",
    "#         print(f\"Frame {frame_id}: Track {track_id} - {info['class_name']} - Mask ID: {mask_id}\")\n",
    "#     \n",
    "#     # Stop after 10 frames for demo\n",
    "#     if frame_id >= 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Disable Masks (Performance Mode)\n",
    "\n",
    "If you need faster processing without mask enhancement, you can disable the mask module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config without masks for faster processing\n",
    "config_fast = BananaTrackerConfig(\n",
    "    yolo_weights=\"/content/HockeyAI_model_weight.pt\",\n",
    "    class_names=[\"Center Ice\", \"Faceoff\", \"Goalpost\", \"Goaltender\", \"Player\", \"Puck\", \"Referee\"],\n",
    "    track_classes=[3, 4, 5, 6],\n",
    "    special_classes=[5],\n",
    "    detection_conf_thresh=0.5,\n",
    "    \n",
    "    # Tracker settings\n",
    "    track_thresh=0.6,\n",
    "    track_buffer=30,\n",
    "    cmc_method=\"orb\",\n",
    "    \n",
    "    # DISABLE mask module\n",
    "    enable_masks=False,\n",
    "    \n",
    "    # Output\n",
    "    output_video_path=\"/content/output_fast.mp4\",\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "# pipeline_fast = BananaTrackerPipeline(config_fast)\n",
    "# all_tracks_fast = pipeline_fast.process_video(INPUT_VIDEO)\n",
    "\n",
    "print(\"Fast mode config created (masks disabled)\")\n",
    "print(\"Uncomment the lines above to run without mask enhancement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                           BananaTracker Pipeline                             │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                              │\n",
    "│  Input Frame                                                                 │\n",
    "│      │                                                                       │\n",
    "│      ▼                                                                       │\n",
    "│  ┌─────────┐                                                                 │\n",
    "│  │ YOLOv8  │ ─────────────────────────────────────────────────────┐         │\n",
    "│  │Detector │                                                       │         │\n",
    "│  └────┬────┘                                                       │         │\n",
    "│       │ Detections [x1,y1,x2,y2,conf,class]                       │         │\n",
    "│       ▼                                                            │         │\n",
    "│  ┌──────────────┐                                                  │         │\n",
    "│  │ BananaTracker│◄─────────── Mask-Enhanced ───────────────────┐   │         │\n",
    "│  │  (ByteTrack) │             Cost Matrix                      │   │         │\n",
    "│  └──────┬───────┘                                              │   │         │\n",
    "│         │ Tracks, New Tracks, Removed IDs                      │   │         │\n",
    "│         ▼                                                      │   │         │\n",
    "│  ┌──────────────────────────────────────────────────────────┐  │   │         │\n",
    "│  │                    MaskManager                            │  │   │         │\n",
    "│  │  ┌───────────┐         ┌─────────┐                       │  │   │         │\n",
    "│  │  │  SAM2.1   │─────────│  Cutie  │                       │  │   │         │\n",
    "│  │  │ (Initial  │  Seed   │(Temporal│                       │  │   │         │\n",
    "│  │  │  Masks)   │  Masks  │ Propag.)│                       │  │   │         │\n",
    "│  │  └───────────┘         └────┬────┘                       │  │   │         │\n",
    "│  │                             │                             │  │   │         │\n",
    "│  │                     prediction_mask                       │──┘   │         │\n",
    "│  │                    tracklet_mask_dict                     │      │         │\n",
    "│  │                    mask_avg_prob_dict                     │      │         │\n",
    "│  └──────────────────────────────────────────────────────────┘      │         │\n",
    "│                                                                     │         │\n",
    "│  ┌─────────────┐                                                   │         │\n",
    "│  │ Visualizer  │◄──────────────────────────────────────────────────┘         │\n",
    "│  │ (with mask  │                                                             │\n",
    "│  │  overlay)   │                                                             │\n",
    "│  └──────┬──────┘                                                             │\n",
    "│         │                                                                    │\n",
    "│         ▼                                                                    │\n",
    "│    Output Frame                                                              │\n",
    "│                                                                              │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "1. **SAM2.1**: Called ONCE per new tracklet to create pixel-precise mask from bounding box\n",
    "2. **Cutie**: Called EVERY frame to propagate masks temporally\n",
    "3. **Mask-Enhanced Cost Matrix**: Uses `mc` (mask coverage) and `mf` (mask fill) metrics to improve association when IoU is ambiguous"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
