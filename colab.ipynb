{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BananaTracker - Optimized Multi-Object Tracking\n",
        "\n",
        "This notebook demonstrates the **optimized** BananaTracker pipeline with:\n",
        "- **Batch YOLO detection** for GPU efficiency\n",
        "- **FP16 inference** for speed\n",
        "- **Optimized ECC** camera motion compensation (BoxMOT pattern)\n",
        "- **SAM2.1 + Cutie** for mask-enhanced tracking\n",
        "\n",
        "## Optimizations Applied:\n",
        "| Optimization | Before | After |\n",
        "|-------------|--------|-------|\n",
        "| Detection Batching | 1 frame | 16 frames |\n",
        "| Precision | FP32 | FP16 |\n",
        "| ECC Iterations | 5000 | 100 |\n",
        "| ECC Scale | 0.5 (2x) | 0.25 (4x) |\n",
        "| Kalman motion_cov | Loop | Vectorized |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics opencv-python-headless tqdm\n",
        "!pip install lap cython_bbox  # For ByteTrack tracker core\n",
        "\n",
        "# Install SAM2.1 dependencies (HuggingFace transformers)\n",
        "!pip install transformers>=4.35.0 huggingface_hub\n",
        "\n",
        "# Install Cutie dependencies\n",
        "!pip install omegaconf hydra-core"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Clone Repositories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Clone BananaTracker repository\n",
        "if not os.path.exists('bananatracker'):\n",
        "    !git clone https://github.com/USER/bananatracker.git\n",
        "\n",
        "# Clone Cutie for temporal mask propagation\n",
        "if not os.path.exists('Cutie'):\n",
        "    !git clone https://github.com/hkchengrex/Cutie.git\n",
        "\n",
        "# Create symlink for Cutie in mask_propagation folder\n",
        "os.makedirs('bananatracker/bananatracker/mask_propagation', exist_ok=True)\n",
        "if not os.path.exists('bananatracker/bananatracker/mask_propagation/Cutie'):\n",
        "    os.symlink('/content/Cutie', 'bananatracker/bananatracker/mask_propagation/Cutie')\n",
        "\n",
        "# Download Cutie weights\n",
        "os.makedirs('Cutie/weights', exist_ok=True)\n",
        "if not os.path.exists('Cutie/weights/cutie-base-mega.pth'):\n",
        "    !wget -P Cutie/weights https://github.com/hkchengrex/Cutie/releases/download/v1.0/cutie-base-mega.pth\n",
        "\n",
        "# Install BananaTracker in development mode\n",
        "%cd bananatracker\n",
        "!pip install -e .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Configuration with Optimizations\n",
        "\n",
        "Configure the optimized tracking pipeline with batch detection and improved ECC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Configuration { display-mode: \"form\" }\n",
        "\n",
        "# Model Settings\n",
        "YOLO_WEIGHTS = \"/content/HockeyAI_model_weight.pt\"  #@param {type:\"string\"}\n",
        "SAM2_MODEL_ID = \"facebook/sam2.1-hiera-large\"  #@param [\"facebook/sam2.1-hiera-tiny\", \"facebook/sam2.1-hiera-small\", \"facebook/sam2.1-hiera-base-plus\", \"facebook/sam2.1-hiera-large\"]\n",
        "CUTIE_WEIGHTS = \"/content/Cutie/weights/cutie-base-mega.pth\"  #@param {type:\"string\"}\n",
        "HF_TOKEN = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "# Optimization Settings\n",
        "USE_BATCH_DETECTION = True  #@param {type:\"boolean\"}\n",
        "DETECTION_BATCH_SIZE = 16  #@param {type:\"integer\"}\n",
        "USE_FP16 = True  #@param {type:\"boolean\"}\n",
        "\n",
        "# ECC Settings (optimized defaults)\n",
        "ECC_MAX_ITERATIONS = 100  #@param {type:\"integer\"}\n",
        "ECC_EPS = 1e-5  #@param {type:\"number\"}\n",
        "ECC_SCALE = 0.25  #@param {type:\"number\"}\n",
        "\n",
        "# Mask Settings\n",
        "ENABLE_MASKS = True  #@param {type:\"boolean\"}\n",
        "\n",
        "print(\"Optimization Settings:\")\n",
        "print(f\"  Batch Detection: {USE_BATCH_DETECTION} (batch_size={DETECTION_BATCH_SIZE})\")\n",
        "print(f\"  FP16 Inference: {USE_FP16}\")\n",
        "print(f\"  ECC: iterations={ECC_MAX_ITERATIONS}, eps={ECC_EPS}, scale={ECC_SCALE} ({int(1/ECC_SCALE)}x downscale)\")\n",
        "print(f\"  Mask Module: {ENABLE_MASKS}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/bananatracker')\n",
        "sys.path.insert(0, '/content/Cutie')\n",
        "\n",
        "from bananatracker import BananaTrackerConfig\n",
        "\n",
        "# Optimized configuration\n",
        "config = BananaTrackerConfig(\n",
        "    # Detection Settings (with FP16 and batch support)\n",
        "    yolo_weights=YOLO_WEIGHTS,\n",
        "    class_names=[\"Center Ice\", \"Faceoff\", \"Goalpost\", \"Goaltender\", \"Player\", \"Puck\", \"Referee\"],\n",
        "    track_classes=[3, 4, 5, 6],  # Goaltender, Player, Puck, Referee\n",
        "    special_classes=[5],          # Puck - max-conf only\n",
        "    detection_conf_thresh=0.4,\n",
        "    detection_iou_thresh=0.7,\n",
        "    detection_batch_size=DETECTION_BATCH_SIZE,\n",
        "    use_half_precision=USE_FP16,\n",
        "\n",
        "    # Centroid deduplication\n",
        "    centroid_dedup_enabled=True,\n",
        "    centroid_dedup_max_distance=36,\n",
        "\n",
        "    # Tracker Settings\n",
        "    track_thresh=0.5,\n",
        "    track_buffer=90,\n",
        "    match_thresh=0.8,\n",
        "\n",
        "    # Camera Motion Compensation (optimized ECC)\n",
        "    cmc_method=\"ecc\",\n",
        "    ecc_max_iterations=ECC_MAX_ITERATIONS,\n",
        "    ecc_termination_eps=ECC_EPS,\n",
        "    ecc_downscale=ECC_SCALE,\n",
        "    cmc_downscale=2,\n",
        "\n",
        "    # Mask Module Settings\n",
        "    enable_masks=ENABLE_MASKS,\n",
        "    sam2_model_id=SAM2_MODEL_ID,\n",
        "    cutie_weights_path=CUTIE_WEIGHTS,\n",
        "    hf_token=HF_TOKEN if HF_TOKEN else None,\n",
        "    mask_start_frame=1,\n",
        "    mask_bbox_overlap_threshold=0.6,\n",
        "    sam2_use_fp16=USE_FP16,\n",
        "\n",
        "    # Visualization\n",
        "    class_colors={\n",
        "        \"Goaltender\": (255, 165, 0),\n",
        "        \"Player\": (255, 0, 0),\n",
        "        \"Puck\": (0, 255, 0),\n",
        "        \"Referee\": (0, 0, 255),\n",
        "    },\n",
        "    show_track_id=True,\n",
        "    show_masks=True,\n",
        "    mask_alpha=0.5,\n",
        "    line_thickness=2,\n",
        "\n",
        "    # Output\n",
        "    output_video_path=\"/content/output_optimized.mp4\",\n",
        "    output_txt_path=\"/content/results.txt\",\n",
        "    device=\"cuda:0\",\n",
        ")\n",
        "\n",
        "print(\"\\nConfiguration created with optimizations!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Initialize Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from bananatracker import BananaTrackerPipeline\n",
        "\n",
        "# Check GPU\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "print()\n",
        "\n",
        "# Initialize pipeline\n",
        "print(\"Initializing pipeline...\")\n",
        "pipeline = BananaTrackerPipeline(config)\n",
        "\n",
        "print(\"\\nPipeline initialized!\")\n",
        "print(f\"  - Detector: YOLOv8 ({'FP16' if config.use_half_precision else 'FP32'})\")\n",
        "print(f\"  - Batch size: {config.detection_batch_size}\")\n",
        "print(f\"  - CMC: ECC (iter={config.ecc_max_iterations}, scale={config.ecc_downscale})\")\n",
        "print(f\"  - Mask module: {'Enabled' if pipeline.mask_manager else 'Disabled'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Run Optimized Batch Processing\n",
        "\n",
        "This uses `process_video_batched()` which batches YOLO inference for GPU efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "INPUT_VIDEO = \"/content/sample_video.mp4\"  # Update with your video path\n",
        "\n",
        "print(f\"Processing: {INPUT_VIDEO}\")\n",
        "print(f\"Batch size: {config.detection_batch_size}\")\n",
        "print(f\"Using {'batched' if USE_BATCH_DETECTION else 'sequential'} detection\")\n",
        "print()\n",
        "\n",
        "# Clear GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if USE_BATCH_DETECTION:\n",
        "    # Use batched processing for GPU efficiency\n",
        "    all_tracks = pipeline.process_video_batched(\n",
        "        INPUT_VIDEO,\n",
        "        batch_size=config.detection_batch_size\n",
        "    )\n",
        "else:\n",
        "    # Standard sequential processing\n",
        "    all_tracks = pipeline.process_video(INPUT_VIDEO)\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "fps = len(all_tracks) / elapsed\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Processing Complete!\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"Frames processed: {len(all_tracks)}\")\n",
        "print(f\"Total time: {elapsed:.1f}s\")\n",
        "print(f\"FPS: {fps:.1f}\")\n",
        "print(f\"Peak GPU memory: {torch.cuda.max_memory_allocated() / 1e9:.1f} GB\")\n",
        "print(f\"\\nOutput video: {config.output_video_path}\")\n",
        "print(f\"MOT results: {config.output_txt_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: Benchmark - Batch vs Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "INPUT_VIDEO = \"/content/sample_video.mp4\"  # Update with your video path\n",
        "TEST_FRAMES = 100  # Number of frames to benchmark\n",
        "\n",
        "# Get frames for testing\n",
        "cap = cv2.VideoCapture(INPUT_VIDEO)\n",
        "frames = []\n",
        "for _ in range(TEST_FRAMES):\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frames.append(frame)\n",
        "cap.release()\n",
        "\n",
        "print(f\"Benchmarking with {len(frames)} frames...\")\n",
        "print()\n",
        "\n",
        "# Benchmark sequential detection\n",
        "torch.cuda.synchronize()\n",
        "start = time.time()\n",
        "for frame in frames:\n",
        "    _ = pipeline.detector.detect(frame)\n",
        "torch.cuda.synchronize()\n",
        "seq_time = time.time() - start\n",
        "seq_fps = len(frames) / seq_time\n",
        "\n",
        "# Benchmark batch detection\n",
        "torch.cuda.synchronize()\n",
        "start = time.time()\n",
        "for i in range(0, len(frames), config.detection_batch_size):\n",
        "    batch = frames[i:i + config.detection_batch_size]\n",
        "    _ = pipeline.detector.detect_batch(batch)\n",
        "torch.cuda.synchronize()\n",
        "batch_time = time.time() - start\n",
        "batch_fps = len(frames) / batch_time\n",
        "\n",
        "print(\"Detection Benchmark Results:\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"Sequential:  {seq_fps:.1f} FPS  ({seq_time:.2f}s)\")\n",
        "print(f\"Batched:     {batch_fps:.1f} FPS  ({batch_time:.2f}s)\")\n",
        "print(f\"Speedup:     {batch_fps/seq_fps:.1f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: Display Output Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Compress video for notebook display\n",
        "OUTPUT_COMPRESSED = \"/content/output_compressed.mp4\"\n",
        "!ffmpeg -y -i {config.output_video_path} -vcodec libx264 -crf 28 {OUTPUT_COMPRESSED}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "OUTPUT_COMPRESSED = \"/content/output_compressed.mp4\"\n",
        "\n",
        "# Read and encode video\n",
        "mp4 = open(OUTPUT_COMPRESSED, 'rb').read()\n",
        "data_url = f\"data:video/mp4;base64,{b64encode(mp4).decode()}\"\n",
        "\n",
        "# Display video\n",
        "HTML(f'''\n",
        "<video width=\"800\" controls>\n",
        "  <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8: GPU Memory Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(\"GPU Memory Status:\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "print(f\"Cached:    {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
        "print(f\"Peak:      {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
        "print(f\"Free:      {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()) / 1e9:.2f} GB\")\n",
        "\n",
        "# Clear cache if needed\n",
        "# torch.cuda.empty_cache()\n",
        "# print(\"\\nCache cleared!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 9: Fast Mode (No Masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration for maximum speed (no masks)\n",
        "config_fast = BananaTrackerConfig(\n",
        "    yolo_weights=YOLO_WEIGHTS,\n",
        "    class_names=[\"Center Ice\", \"Faceoff\", \"Goalpost\", \"Goaltender\", \"Player\", \"Puck\", \"Referee\"],\n",
        "    track_classes=[3, 4, 5, 6],\n",
        "    special_classes=[5],\n",
        "    detection_conf_thresh=0.4,\n",
        "    detection_batch_size=32,  # Larger batch for max GPU utilization\n",
        "    use_half_precision=True,\n",
        "    \n",
        "    # Fast CMC\n",
        "    cmc_method=\"orb\",  # ORB is faster than ECC\n",
        "    cmc_downscale=4,\n",
        "    \n",
        "    # Disable masks for speed\n",
        "    enable_masks=False,\n",
        "    \n",
        "    # Output\n",
        "    output_video_path=\"/content/output_fast.mp4\",\n",
        "    device=\"cuda:0\",\n",
        ")\n",
        "\n",
        "print(\"Fast mode config created:\")\n",
        "print(f\"  - Batch size: {config_fast.detection_batch_size}\")\n",
        "print(f\"  - FP16: {config_fast.use_half_precision}\")\n",
        "print(f\"  - CMC: {config_fast.cmc_method} ({config_fast.cmc_downscale}x downscale)\")\n",
        "print(f\"  - Masks: Disabled\")\n",
        "print(\"\\nUncomment below to run fast mode:\")\n",
        "\n",
        "# pipeline_fast = BananaTrackerPipeline(config_fast)\n",
        "# all_tracks_fast = pipeline_fast.process_video_batched(INPUT_VIDEO, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Expected Performance\n",
        "\n",
        "| Configuration | GPU Memory | FPS (estimate) |\n",
        "|--------------|------------|----------------|\n",
        "| Original (FP32, no batch, ECC 5000 iter) | ~7 GB | ~5-10 |\n",
        "| Optimized (FP16, batch=16, ECC 100 iter) | ~15-20 GB | ~25-40 |\n",
        "| Fast mode (FP16, batch=32, ORB, no masks) | ~10-15 GB | ~50-80 |\n",
        "\n",
        "Actual performance depends on:\n",
        "- GPU model (A100, V100, T4, etc.)\n",
        "- Video resolution\n",
        "- Number of objects per frame\n",
        "- Whether masks are enabled"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
